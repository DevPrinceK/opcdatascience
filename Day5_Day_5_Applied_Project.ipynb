{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10764f8f",
   "metadata": {},
   "source": [
    "# Day 5 — Applied Data Science: From Data to Insights\n",
    "\n",
    "**Duration:** 2 hours\n",
    "\n",
    "**Objectives:**\n",
    "- Run an end-to-end mini-project (Titanic)\n",
    "- Practice cleaning, EDA, modeling, evaluation\n",
    "- Prepare deliverables for the take-home assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6de5ae",
   "metadata": {},
   "source": [
    "## 1. Project Overview\n",
    "\n",
    "**Dataset:** Titanic (from seaborn)\n",
    "**Goal:** Predict `survived` using features. Deliverables: a Jupyter notebook and a 1-page summary report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f59c4b7",
   "metadata": {},
   "source": [
    "## 2. Step-by-step pipeline (we'll follow this in the notebook)\n",
    "1. Load data\n",
    "2. Inspect and clean\n",
    "3. Feature engineering\n",
    "4. Visualize (EDA)\n",
    "5. Train two models (Logistic Regression, Decision Tree)\n",
    "6. Evaluate and compare\n",
    "7. Summarize findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and quick inspection\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "print('Shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bbc80a",
   "metadata": {},
   "source": [
    "## 3. Cleaning (suggested)\n",
    "- Impute `age` with median\n",
    "- Fill `embarked` with mode\n",
    "- Encode `sex` and `class` (one-hot or ordinal)\n",
    "- Drop unused columns (e.g., `deck`, `embark_town` if desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de60498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning steps\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "notebook_df = df[['survived','pclass','sex','age','fare','embarked']].copy()\n",
    "# Impute age\n",
    "imp = SimpleImputer(strategy='median')\n",
    "notebook_df['age'] = imp.fit_transform(notebook_df[['age']])\n",
    "# Impute embarked\n",
    "imp2 = SimpleImputer(strategy='most_frequent')\n",
    "notebook_df['embarked'] = imp2.fit_transform(notebook_df[['embarked']])\n",
    "# Encode sex\n",
    "notebook_df['sex'] = notebook_df['sex'].map({'male':0,'female':1})\n",
    "# One-hot embarked\n",
    "notebook_df = pd.get_dummies(notebook_df, columns=['embarked'], prefix='emb')\n",
    "notebook_df = notebook_df.dropna()\n",
    "notebook_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1679225c",
   "metadata": {},
   "source": [
    "## 4. EDA — Visualizations\n",
    "\n",
    "Create plots to show relationships and distributions. Examples: survival rate by sex, age histogram, survival by fare bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2567131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA visuals\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='sex', hue='survived', data=notebook_df)\n",
    "plt.title('Survival by sex')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "notebook_df['age'].hist(bins=20)\n",
    "plt.title('Age distribution')\n",
    "plt.show()\n",
    "\n",
    "# Survival by fare bins\n",
    "bins=[0,10,20,50,100,600]\n",
    "labels=['0-10','10-20','20-50','50-100','100+']\n",
    "notebook_df['fare_bin'] = pd.cut(notebook_df['fare'].fillna(0), bins=bins, labels=labels)\n",
    "surv_by_fare = notebook_df.groupby('fare_bin')['survived'].mean().reset_index()\n",
    "sns.barplot(x='fare_bin', y='survived', data=surv_by_fare)\n",
    "plt.title('Survival rate by Fare bin')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000eb94f",
   "metadata": {},
   "source": [
    "## 5. Modeling: train Logistic Regression & Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdecd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling & evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "features = ['pclass','sex','age','fare']\n",
    "X = notebook_df[features]\n",
    "y = notebook_df['survived'].astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print('Logistic Regression accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print('Decision Tree accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e8c98",
   "metadata": {},
   "source": [
    "## 6. Interpret & Compare\n",
    "\n",
    "Compare accuracy, recall, precision. Discuss which model you would prefer and why (consider domain costs: false negatives vs false positives)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc311d6f",
   "metadata": {},
   "source": [
    "## 7. Take-Home Assignment (deliverables)\n",
    "\n",
    "**Individual task (due in 1 week):**\n",
    "- Use the Titanic dataset (or Iris if preferred).\n",
    "- Clean and preprocess the data.\n",
    "- Create at least 3 EDA visualizations with short captions/insights.\n",
    "- Train **two** models (one linear/simple, one tree-based or ensemble).\n",
    "- Compare their performance using at least two metrics (accuracy & recall or F1).\n",
    "- Submit:\n",
    "  1. Jupyter Notebook (.ipynb) with code and outputs.\n",
    "  2. One-page PDF/Markdown summary: problem, approach, results, insights.\n",
    "\n",
    "**Bonus (optional):** Try feature engineering (create new features) and report impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c7cc1",
   "metadata": {},
   "source": [
    "## 8. Starter checklist & tips\n",
    "\n",
    "- Use train/test split and consider cross-validation for robustness.\n",
    "- Document every preprocessing step.\n",
    "- When in doubt, visualize the data.\n",
    "- Keep reproducible code: set random_state where appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c123c8e",
   "metadata": {},
   "source": [
    "## 9. Course Wrap-up\n",
    "\n",
    "Congratulations — you completed the 5-day crash/refresher! Good luck with the take-home assignment. Reach out if you need help."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
