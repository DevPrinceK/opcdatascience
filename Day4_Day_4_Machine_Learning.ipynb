{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae242aa",
   "metadata": {},
   "source": [
    "# Day 4 — Machine Learning Foundations\n",
    "\n",
    "**Duration:** 2 hours\n",
    "\n",
    "**Objectives:**\n",
    "- Understand supervised vs unsupervised learning\n",
    "- Train a simple classifier and evaluate it\n",
    "- Learn basic ML workflow and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a4cd9",
   "metadata": {},
   "source": [
    "## 1. Quick recap of ML concepts\n",
    "\n",
    "- Supervised (regression, classification)\n",
    "- Unsupervised (clustering, dim. reduction)\n",
    "- Reinforcement (agent-based)\n",
    "\n",
    "Today we'll focus on supervised classification with Logistic Regression and Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f807fd",
   "metadata": {},
   "source": [
    "## 2. Dataset: Titanic (classification task)\n",
    "\n",
    "Goal: predict `survived` using a few chosen features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9563f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load and prepare data\n",
    "titanic = sns.load_dataset('titanic')\n",
    "df = titanic[['survived','pclass','sex','age','fare']].copy()\n",
    "# simple preprocessing: drop rows with missing survived\n",
    "# impute age with median\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='median')\n",
    "df['age'] = imp.fit_transform(df[['age']])\n",
    "# encode sex and pclass\n",
    "df['sex'] = df['sex'].map({'male':0,'female':1})\n",
    "# pclass already numeric\n",
    "# drop remaining nulls if any\n",
    "df = df.dropna()\n",
    "\n",
    "X = df[['pclass','sex','age','fare']]\n",
    "y = df['survived'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe09c0b",
   "metadata": {},
   "source": [
    "## 3. Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=200)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "print('Logistic Regression accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d371c0",
   "metadata": {},
   "source": [
    "## 4. Train Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aab26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print('Decision Tree accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3eedf0",
   "metadata": {},
   "source": [
    "## 5. Confusion Matrix (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_lr)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceedda5",
   "metadata": {},
   "source": [
    "## 6. Feature importance / coefficients\n",
    "\n",
    "Interpret model coefficients for logistic regression (which features push survival up/down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4eeb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.DataFrame({'feature': X.columns, 'coef': lr.coef_[0]})\n",
    "coeffs.sort_values('coef', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98515165",
   "metadata": {},
   "source": [
    "## 7. Overfitting vs Underfitting (demo idea)\n",
    "\n",
    "We used a shallow decision tree (max_depth=5) to reduce overfitting. Try increasing depth to see what happens. For homework, experiment with tree depth and record train vs test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348bdc51",
   "metadata": {},
   "source": [
    "## 8. Exercise (in-notebook)\n",
    "\n",
    "1. Train a k-Nearest Neighbors classifier (k=5) on the same data. Compare accuracy.\n",
    "2. Try scaling `age` and `fare` with StandardScaler and re-run Logistic Regression. Observe any change.\n",
    "3. (Optional) Use cross-validation to estimate performance more reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57195f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise starters: KNN + scaling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "print('KNN accuracy:', accuracy_score(y_test, knn.predict(X_test)))\n",
    "\n",
    "# Scaling + Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr2 = LogisticRegression(max_iter=200)\n",
    "lr2.fit(X_train_scaled, y_train)\n",
    "print('LogReg (scaled) accuracy:', accuracy_score(y_test, lr2.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508f28f",
   "metadata": {},
   "source": [
    "## 9. Wrap-up & Reading\n",
    "\n",
    "Suggested: Hands-On Machine Learning with Scikit-Learn & TensorFlow (Aurélien Géron). Tomorrow: Day 5 — Applied project & take-home assignment."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
